{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform text classificaiton using bag of words and finally load this as input into Fully connected layers of Neural Net. We shall use pandas,numpy for data operations and Keras for Fully connected layers of neural net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform below steps\n",
    "1. Clean Training data for punctuations and standard stopwords\n",
    "2. Create vocab list \n",
    "3. Convert text to matrix usng Keras Tokenizer\n",
    "4. Train neural net \n",
    "5. Predicton on test data and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import DataFrame\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Conv1D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn a text into clean tokens\n",
    "def clean_text(text):\n",
    "    # remove punctuation from the text\n",
    "    text = text.replace(\"' \", \" ' \")\n",
    "    signs = set(',.:;\"?!')\n",
    "    prods = set(text) & signs\n",
    "    if not prods:\n",
    "        return text\n",
    "    for sign in prods:\n",
    "        text = text.replace(sign, ' {} '.format(sign) )\n",
    "    # split into tokens by white space\n",
    "    tokens = text.split()\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filter out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define column names\n",
    "TEXT =\"text\"\n",
    "AUTHOR = \"author\"\n",
    "\n",
    "# Create fucntion to load words into vocab\n",
    "\n",
    "def add_text_to_vocab(X_train, vocab):\n",
    "    for text in X_Train[TEXT]:\n",
    "      tokens = clean_text(text)\n",
    "      # update counts\n",
    "      vocab.update(tokens)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will load the training data, clean up each text and load create a vocab list after filtering on punctuations, stopwords,short length tokens and minimum occurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read text from training data\n",
    "X_Train= pd.read_csv(\"train.csv\")\n",
    "\n",
    "# define vocab\n",
    "vocab = Counter()\n",
    "\n",
    "# add all text to vocab\n",
    "add_text_to_vocab(X_Train,vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep tokens with a min occurrence \n",
    "min_occurane = 2\n",
    "tokens = [k for k,c in vocab.items() if c >= min_occurane]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocab list is now created. We will store that into a file for further reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list to file\n",
    "def save_list(lines, filename):\n",
    "    # convert lines to a single blob of text\n",
    "    data = '\\n'.join(lines)\n",
    "    # open file\n",
    "    file = open(filename, 'w')\n",
    "    # write text\n",
    "    file.write(data)\n",
    "    # close file\n",
    "    file.close()\n",
    "\n",
    "# save tokens to a vocabulary file\n",
    "save_list(tokens, 'vocab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file into memory\n",
    "def load_file(filename):\n",
    "    # open the file as read only\n",
    "    file = open(filename, 'r')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    # close the file\n",
    "    file.close()\n",
    "    return text\n",
    "\n",
    "# load the vocabulary back into memory to be used for model training\n",
    "vocab_filename = 'vocab.txt'\n",
    "vocab = load_file(vocab_filename)\n",
    "vocab = vocab.split()\n",
    "vocab = set(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can start data preparation for model training. We will use Keras Tokenizer with mode as 'freq', I have tried Binary, count and tfidf as well. Freq modes seems to work best with lowest loss among these options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# prepare bag of words encoding of docs\n",
    "def prepare_data(train_docs, mode):\n",
    "    # fit the tokenizer on the documents\n",
    "    tokenizer.fit_on_texts(train_docs)\n",
    "    # encode training data set\n",
    "    Xtrain = tokenizer.texts_to_matrix(train_docs, mode=mode)\n",
    "    return Xtrain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create neural network definition model with Keras. This will include multiple set of Dense, BatchNorm, Activation and dropout layer. You can decide on number of layers. \n",
    "\n",
    "Dropout is included in input latyer and hidden layers to reduce variance and overfitting on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a neural network model\n",
    "def create_model(xtrain):\n",
    "    \n",
    "    X_input = Input(shape=(xtrain.shape[1],))\n",
    "   \n",
    "    # dropout on input layer\n",
    "    X = Dropout(0.5)(X_input)\n",
    "    \n",
    "    # Dense -> BN -> RELU-> Dropout Block applied to X - First set\n",
    "    X = Dense(900, kernel_initializer='he_normal', name='D0')(X)\n",
    "    X = BatchNormalization(axis=1, name='bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    # Dense -> BN -> RELU-> Dropout Block applied to X - Second set\n",
    "    X = Dense(600, kernel_initializer='he_normal', name='D1')(X)\n",
    "    X = BatchNormalization(axis=1, name='bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    # Dense -> BN -> RELU-> Dropout Block applied to X - Third set\n",
    "    X = Dense(300, kernel_initializer='he_normal', name='D2')(X)\n",
    "    X = BatchNormalization(axis=1, name='bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    # output layer with softmax function for 3 classes prediction\n",
    "    X = Dense(3, kernel_initializer='he_normal', activation='softmax')(X)\n",
    "\n",
    "    Spookymodel = Model(inputs=X_input, outputs=X, name='SpookyAuthor')\n",
    "    \n",
    "    return Spookymodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to transform training data and create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare data and and create model \n",
    "# You can try with other modes 'binary','count','tfidf'\n",
    "modes = 'freq'\n",
    "\n",
    "#Training \n",
    "train_texts = X_Train[TEXT]\n",
    "# Training labels (coverted into seperate columsn for each other with 0,1)\n",
    "ytrain = np.array(pd.get_dummies(X_Train[AUTHOR]))\n",
    "\n",
    "# prepare data for mode\n",
    "xtrain = prepare_data(train_texts, mode)\n",
    "\n",
    "# model defination creation\n",
    "Spookymodel = create_model(xtrain)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 25944)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 25944)             0         \n",
      "_________________________________________________________________\n",
      "D0 (Dense)                   (None, 900)               23350500  \n",
      "_________________________________________________________________\n",
      "bn0 (BatchNormalization)     (None, 900)               3600      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 900)               0         \n",
      "_________________________________________________________________\n",
      "D1 (Dense)                   (None, 600)               540600    \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 600)               2400      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "D2 (Dense)                   (None, 300)               180300    \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 903       \n",
      "=================================================================\n",
      "Total params: 24,079,503\n",
      "Trainable params: 24,075,903\n",
      "Non-trainable params: 3,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "Spookymodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to the model. Let's complie and train the model.\n",
    "\n",
    "Optimizer - We will use \"Adamax\" optimizer with learning rate of 0.05 and rate decay of 0.001. You can tune these as per your preferences.\n",
    "\n",
    "Loss function - Categorical_crossentropy.\n",
    "\n",
    "Batch size - 64\n",
    "\n",
    "validation split- 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15663 samples, validate on 3916 samples\n",
      "Epoch 1/25\n",
      "198s - loss: 0.3545 - acc: 0.8660 - val_loss: 0.4128 - val_acc: 0.8501\n",
      "Epoch 2/25\n",
      "196s - loss: 0.3650 - acc: 0.8659 - val_loss: 0.4121 - val_acc: 0.8501\n",
      "Epoch 3/25\n",
      "195s - loss: 0.3611 - acc: 0.8720 - val_loss: 0.4099 - val_acc: 0.8506\n",
      "Epoch 4/25\n",
      "226s - loss: 0.3668 - acc: 0.8703 - val_loss: 0.4098 - val_acc: 0.8519\n",
      "Epoch 5/25\n",
      "226s - loss: 0.3704 - acc: 0.8646 - val_loss: 0.4112 - val_acc: 0.8519\n",
      "Epoch 6/25\n",
      "225s - loss: 0.3623 - acc: 0.8682 - val_loss: 0.4134 - val_acc: 0.8493\n",
      "Epoch 7/25\n",
      "225s - loss: 0.3657 - acc: 0.8668 - val_loss: 0.4138 - val_acc: 0.8509\n",
      "Epoch 8/25\n",
      "225s - loss: 0.3564 - acc: 0.8659 - val_loss: 0.4100 - val_acc: 0.8532\n",
      "Epoch 9/25\n",
      "225s - loss: 0.3631 - acc: 0.8690 - val_loss: 0.4124 - val_acc: 0.8529\n",
      "Epoch 10/25\n",
      "225s - loss: 0.3678 - acc: 0.8682 - val_loss: 0.4165 - val_acc: 0.8506\n",
      "Epoch 11/25\n",
      "226s - loss: 0.3626 - acc: 0.8690 - val_loss: 0.4142 - val_acc: 0.8504\n",
      "Epoch 12/25\n",
      "226s - loss: 0.3578 - acc: 0.8720 - val_loss: 0.4169 - val_acc: 0.8491\n",
      "Epoch 13/25\n",
      "225s - loss: 0.3631 - acc: 0.8678 - val_loss: 0.4155 - val_acc: 0.8496\n",
      "Epoch 14/25\n",
      "225s - loss: 0.3646 - acc: 0.8666 - val_loss: 0.4113 - val_acc: 0.8521\n",
      "Epoch 15/25\n",
      "226s - loss: 0.3607 - acc: 0.8672 - val_loss: 0.4139 - val_acc: 0.8509\n",
      "Epoch 16/25\n",
      "224s - loss: 0.3502 - acc: 0.8727 - val_loss: 0.4127 - val_acc: 0.8516\n",
      "Epoch 17/25\n",
      "225s - loss: 0.3605 - acc: 0.8684 - val_loss: 0.4177 - val_acc: 0.8491\n",
      "Epoch 18/25\n",
      "200s - loss: 0.3562 - acc: 0.8700 - val_loss: 0.4122 - val_acc: 0.8524\n",
      "Epoch 19/25\n",
      "194s - loss: 0.3620 - acc: 0.8661 - val_loss: 0.4115 - val_acc: 0.8519\n",
      "Epoch 20/25\n",
      "194s - loss: 0.3491 - acc: 0.8720 - val_loss: 0.4124 - val_acc: 0.8506\n",
      "Epoch 21/25\n",
      "195s - loss: 0.3565 - acc: 0.8716 - val_loss: 0.4124 - val_acc: 0.8511\n",
      "Epoch 22/25\n",
      "194s - loss: 0.3700 - acc: 0.8646 - val_loss: 0.4139 - val_acc: 0.8493\n",
      "Epoch 23/25\n",
      "194s - loss: 0.3614 - acc: 0.8675 - val_loss: 0.4134 - val_acc: 0.8509\n",
      "Epoch 24/25\n",
      "194s - loss: 0.3603 - acc: 0.8704 - val_loss: 0.4115 - val_acc: 0.8511\n",
      "Epoch 25/25\n",
      "195s - loss: 0.3696 - acc: 0.8651 - val_loss: 0.4139 - val_acc: 0.8516\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAFvdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17f85af60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimzer = optimizers.Adamax(lr=0.0001, beta_1=0.9, beta_2=0.99, epsilon=1e-08, decay=0.001)\n",
    "\n",
    "# compile network\n",
    "Spookymodel.compile(loss='categorical_crossentropy', optimizer=optimzer, metrics=['accuracy'])\n",
    "\n",
    "# fitnetwork\n",
    "train_history = Spookymodel.fit(x= xtrain, y=ytrain, epochs=25,verbose=2,batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Plot the training and validation loss at each epoch\n",
    "loss = train_history.history['loss']\n",
    "val_loss = train_history.history['val_loss']\n",
    "pyplot.plot(loss)\n",
    "pyplot.plot(val_loss)\n",
    "pyplot.legend(['loss', 'val_loss'])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation loss of 0.43 is achieved with 5 epochs. It can be minimized further with hyperparameter tunning and more training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer conv1d_3: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-d8dc0c042d60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mConvNetmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m ConvNetmodel.add(Conv1D(32, (3), padding='same',\n\u001b[0;32m----> 3\u001b[0;31m                  input_shape=xtrain.shape[1:]))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mConvNetmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mConvNetmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Tensorflow/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Tensorflow/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Tensorflow/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    455\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer conv1d_3: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "ConvNetmodel = Sequential()\n",
    "ConvNetmodel.add(Conv1D(32, (3), padding='same',\n",
    "                 input_shape=xtrain.shape[1:]))\n",
    "ConvNetmodel.add(Activation('relu'))\n",
    "ConvNetmodel.add(Conv1D(32, (3)))\n",
    "ConvNetmodel.add(Activation('relu'))\n",
    "ConvNetmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "ConvNetmodel.add(Dropout(0.25))\n",
    "\n",
    "ConvNetmodel.add(Conv1D(64, (3), padding='same'))\n",
    "ConvNetmodel.add(Activation('relu'))\n",
    "ConvNetmodel.add(Conv1D(64, (3)))\n",
    "ConvNetmodel.add(Activation('relu'))\n",
    "ConvNetmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "ConvNetmodel.add(Dropout(0.25))\n",
    "\n",
    "ConvNetmodel.add(Flatten())\n",
    "ConvNetmodel.add(Dense(512))\n",
    "ConvNetmodel.add(Activation('relu'))\n",
    "ConvNetmodel.add(Dropout(0.5))\n",
    "ConvNetmodel.add(Dense(3))\n",
    "ConvNetmodel.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer zero_padding2d_4: expected ndim=4, found ndim=3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-d3cf8017ad5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# model defination creation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mSpookymodel_ConvNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-60e908c6b712>\u001b[0m in \u001b[0;36mConvNet_model\u001b[0;34m(xtrain)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Zero-Padding: pads the border of X_input with zeroes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZeroPadding2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# CONV -> BN -> RELU Block applied to X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Tensorflow/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Tensorflow/lib/python3.5/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    455\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer zero_padding2d_4: expected ndim=4, found ndim=3"
     ]
    }
   ],
   "source": [
    "#Prepare data and and create model \n",
    "# You can try with other modes 'binary','count','tfidf'\n",
    "modes = 'freq'\n",
    "\n",
    "#Training \n",
    "train_texts = X_Train[TEXT]\n",
    "# Training labels (coverted into seperate columsn for each other with 0,1)\n",
    "ytrain = np.array(pd.get_dummies(X_Train[AUTHOR]))\n",
    "\n",
    "# prepare data for mode\n",
    "xtrain = prepare_data(train_texts, mode)\n",
    "\n",
    "# model defination creation\n",
    "Spookymodel_ConvNet = ConvNet_model(xtrain)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction on test data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to predict on test data and submit the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the author class on test data\n",
    "def predict_author(text, vocab,tokenizer, model):\n",
    "    # clean\n",
    "    tokens = clean_text(text)\n",
    "    # filter by vocab\n",
    "    tokens = [w for w in tokens if w in vocab]\n",
    "    # convert to line\n",
    "    line = ' '.join(tokens)\n",
    "    # encode\n",
    "    encoded = tokenizer.texts_to_matrix([line], mode='freq')\n",
    "    # prediction\n",
    "    yhat = model.predict(encoded, verbose=0)\n",
    "    return yhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data into dataframe\n",
    "X_sub = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Initilize prediction matrix \n",
    "y_pred = np.zeros((X_sub.shape[0],3))\n",
    "\n",
    "# Predict for each  sample in test dataset\n",
    "i = 0\n",
    "for text in X_sub[TEXT]:\n",
    "    y_pred[i]=predict_author(text,vocab,tokenizer,Spookymodel)\n",
    "    i +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating submission datafram\n",
    "submission = pd.DataFrame(y_pred,dtype=float)\n",
    "submission=submission.rename(index=int, columns={0: \"EAP\", 1: \"HPL\", 2: \"MWS\"})\n",
    "submission.insert(0,'id',X_sub[\"id\"])\n",
    "\n",
    "\n",
    "#Save as CSV file for submission\n",
    "submission.to_csv(\"sub.csv\",sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
